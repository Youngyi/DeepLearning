{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特殊应用：人脸识别 & 神经风格迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 人脸识别 Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 什么是人脸识别 What is face recognition?\n",
    "\n",
    "一个商用的人脸识别系统，通常包含人脸识别（确保是人脸）和活体检测（确保是真人而不是人脸的图片）。本章将会主要关注狭义的人脸识别。而活体检测也是可以用监督学习来做的。\n",
    "\n",
    "人脸验证（face verification）和人脸识别（face recognition）也是经常用来相互区分的一组概念。当人脸验证算法的准确率足够高时，它就可以用来构建一个人脸识别算法。\n",
    "\n",
    "![Face verification vs face recognition.png](img/Face verification vs face recognition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 一次性学习 One Shot Learning\n",
    "\n",
    "对于人脸验证问题，每个人只有一张图片，由于样本量很小，很难训练出稳定的接受新图片，判断是否在图片库内的卷积神经网络模型。同时，由于图片库会更新，增加或减少样本时，需要修改Softmax层的神经元数量重新训练，也比较麻烦。\n",
    "![One-shot learning.png](img/One-shot learning.png)\n",
    "\n",
    "取而代之，在人脸验证问题中，我们会用神经网络训练一个模型，接受两张图片作为参数，输出它们的相似度。\n",
    "![Learning a similarity function.png](img/Learning a similarity function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3 Siamese网络 Siamese Network\n",
    "\n",
    "计算人脸图片相似度常用的方法是Siamese网络。它运用神经网络，对一张图片输出一个特征向量。然后通过比对不同图片的特征向量，比对不同图片的相似度。\n",
    "\n",
    "![Siamese Network.png](img/Siamese Network.png)\n",
    "\n",
    "![Goal of learning.png](img/Goal of learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Triplet Loss\n",
    "\n",
    "训练Siamese网络，损失函数规范地定义为Triplet Loss。它需要三个样本，Anchor锚点，Positive正类，Negative反类。其中Archor和Positive是同一个人，而Archor和Negative不是同一个人。我们需要Archor和正类的差异远小于Archor和反类的差异。\n",
    "\n",
    "这里 $\\alpha$ 叫做间隔，它作为超参存在。因为当 $\\alpha=0$ 时，算法可能会让 $f$ 始终输出0，也满足下面的不等式，但那不是我们想要的。\n",
    "\n",
    "![Learning Objective.png](img/Learning Objective.png)\n",
    "\n",
    "![Loss function.png](img/Loss function.png)\n",
    "\n",
    "训练样本需要包含同一个人的多张照片。而从训练样本中挑选 $A,P,N$ 也有一定的技巧。随机挑选后训练出来的算法可能效果不会特别好。\n",
    "\n",
    "![Choosing the triplets APN.png](img/Choosing the triplets APN.png)\n",
    "\n",
    "![Training set using triplet loss.png](img/Training set using triplet loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 人脸验证和二分类 Face Verification and Binary Classification\n",
    "\n",
    "相比使用Triplet Loss的方法，也可以直接训练一个逻辑回归。用卷积神经网络产出的特征向量作为输入，输出是否同一个人。\n",
    "\n",
    "![Learning the similarity function.png](img/Learning the similarity function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 神经风格迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 什么是神经风格迁移\n",
    "\n",
    "![Neural style transfer.png](img/Neural style transfer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 深度卷积网络在学什么\n",
    "\n",
    "![Visualizing what a deep network is learning.png](img/Visualizing what a deep network is learning.png)\n",
    "\n",
    "![Visualizing deep layers.png](img/Visualizing deep layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 成本函数 Cost Function\n",
    "\n",
    "![Neural style transfer cost function.png](img/Neural style transfer cost function.png)\n",
    "\n",
    "![Find the generated  image G.png](img/Find the generated  image G.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
