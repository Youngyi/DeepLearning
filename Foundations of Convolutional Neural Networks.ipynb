{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 计算机视觉\n",
    "\n",
    "随着深度学习的兴起，近些年来计算机视觉领域的发展十分迅猛。一方面，深度学习在计算机视觉的应用，使得很多几年前还无法解决的领域问题得以解决，比如人脸识别、自动驾驶；另一方面，在实践中计算机视觉社区对深度学习技巧的发现，也常常可以应用到其它领域里。\n",
    "\n",
    "计算机视觉领域的典型问题，包括图片分类、物体检测、神经风格迁移等。\n",
    "\n",
    "![Computer Vision Problems.png](img/Computer Vision Problems.png)\n",
    "\n",
    "由于图像数据的特点（高分辨率，特征多），非常容易多拟合，同时针对图像数据训练模型也需要极大的计算资源。而要使用高分辨率的图片训练模型，最好要实现卷积，卷积是卷积神经网络的基本组成单元。\n",
    "\n",
    "![Deep Learning on large images.png](img/Deep Learning on large images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.2 边缘检测实例\n",
    "\n",
    "在之前介绍的人类识别神经网络中，我们发现最终训练完成的神经网络会首先形成边缘检测的底层特征，在此基础上继续构建五官检测，进而再到人脸检测。可以说边缘检测是非常基础性的步骤。\n",
    "\n",
    "![Computer Vision Problem.png](img/Computer Vision Problem.png)\n",
    "\n",
    "卷积操作可以有效地进行边缘检测。卷积计算用到的这个3×3的矩阵，称为**过滤器 filter**，有些文献中也称为**核 kernel**。\n",
    "\n",
    "![Vertical edge detection.png](img/Vertical edge detection.png)\n",
    "\n",
    "卷积操作检测出来的边缘看起来比较粗，当输入图片的分辨率非常高时，这点损耗可以忽略不计。\n",
    "\n",
    "![Vertical edge detection 2.png](img/Vertical edge detection 2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3 更多边缘检测的内容\n",
    "\n",
    "上面提到的过滤器，还可以区分由浅到深的边缘和由深到浅的边缘。\n",
    "\n",
    "![Vertical edge detection examples.png](img/Vertical edge detection examples.png)\n",
    "\n",
    "而将这个过滤器的矩阵转置，就是水平边缘检测的过滤器。\n",
    "\n",
    "![Vertical and Horizontal Edge Detection.png](img/Vertical and Horizontal Edge Detection.png)\n",
    "\n",
    "除去水平边缘和垂直边缘过滤器外，计算机视觉社区还发明过Sober过滤器和Scharr过滤器，它们分别有一些自己的特性。而在深度学习时代，一个非常重要的理念是，过滤器本身可以作为神经网络的参数，在反向传播的过程中进行学习。这样最终学得的边缘检测过滤器，可能不限于水平或垂直边缘，而是可以检测任意倾斜的边缘。\n",
    "\n",
    "![Learning to detect edges.png](img/Learning to detect edges.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 补全\n",
    "\n",
    "经过卷积操作，图片的分辨率会降低。如果原图是n×n的矩阵，而过滤器是f×f的矩阵，卷积之后的矩阵就变为了(n-f+1)×(n-f+1)维。这样有两个坏处：1）随着每一层神经网络的卷积计算，图片的大小都在不断缩小，限制了训练过大的神经网络；2）角和边上的像素点，参与卷积计算的次数会更少，从而造成边角的信息利用率低。所以实际使用中，卷积通常伴随着补全。\n",
    "\n",
    "![Padding.png](img/Padding.png)\n",
    "\n",
    "根据使用补全的策略，区分**正确卷积 Valid convolution**和**同一卷积 Same convolution**。所谓正确卷积，就是不包含补全，任由图片大小缩减；而同一卷积，是先进行补全，使得最终输出的图片大小和输入一致。注意要同一卷积的要求，使得 $p=\\frac{f-1}{2}$。这就要求过滤器是一个奇数维的矩阵，否则补全就需要是非对称的。过滤器是奇数维矩阵的另一个好处，是过滤器存在一个中心像素，方便定位位置。\n",
    "\n",
    "![Valid and Same convolutions.png](img/Valid and Same convolutions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 步长\n",
    "\n",
    "前面看到的卷积操作，过滤器每次都只移动一格。而引入步长的概念之后，过滤器每次可以移动不只一格。\n",
    "\n",
    "![Strided convolution.png](img/Strided convolution.png)\n",
    "\n",
    "在有补全和步长的情况下，输出的数据量大小也会有所变化。\n",
    "\n",
    "![Summary of convolutions.png](img/Summary of convolutions.png)\n",
    "\n",
    "从严格数学的定义来说，实际上我们上面用到的应该称为**交叉相关性 cross-correlation**，而真正的卷积，在交叉相关性之前，还需要先进行垂直和水平的翻转，这样可以使得卷积服从结合律。不过这个特性对于神经网络意义不大（对于信号处理中使用卷积比较有用），所以在深度学习社区，实际上使用卷积时，并不会进行翻转，但是从命名习惯上，依然将其称之为卷积。\n",
    "\n",
    "![Technical note on cross-correlation vs convolution.png](img/Technical note on cross-correlation vs convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 高维空间的卷积\n",
    "\n",
    "对于图片，如果要处理RGB值，就会有三个n×n的矩阵，形成一个n×n×3的立方体，这时相应的，过滤器也变成了一个f×f×3的立方体，最终输出仍然是一个矩阵。\n",
    "\n",
    "![Convolutions on RGB image.png](img/Convolutions on RGB image.png)\n",
    "\n",
    "在需要的情况下，也可以同时使用多个过滤器。\n",
    "\n",
    "![Multiple filters.png](img/Multiple filters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.7 一层卷积神经网络\n",
    "\n",
    "![Example of a layer.png](img/Example of a layer.png)\n",
    "\n",
    "![Summary of notation.png](img/Summary of notation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.8 简单的卷积神经网络示例\n",
    "\n",
    "一个39×39像素，RGB三通道表示的图片，经过三个卷积层，最后叠加一层logistic或softmax的卷机神经网络分类模型。注意到随着层数的增加，图片的像素在下降，而通道数在上升，这也是超参选择（每一层的过滤器大小f，过滤器数量$n_c$，步长s，补全p）的一个普遍趋势。\n",
    "\n",
    "![Example ConvNet.png](img/Example ConvNet.png)\n",
    "\n",
    "实际上，一个典型的卷积神经网络，除去卷积层之外，还会包含池化层(Pooling)，完全连接层(Fully connected)。下面会详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.9 池化层\n",
    "\n",
    "在过滤器区间内，取最大值，称为最大池化层。\n",
    "\n",
    "![Pooling layer Max pooling.png](img/Pooling layer Max pooling.png)\n",
    "\n",
    "池化层和卷积层的一个显著不同，是池化层的过滤器是针对通道独立的，不会跨通道取最大值。过滤器也包含两个超参，分别是f过滤器大小和步长s。注意和卷积层的另一个不同，是池化层的过滤器，只有超参，没有参数。所以在反向传播的过程中，这一层是没有更新的。\n",
    "\n",
    "![Pooling layer Max pooling 2.png](img/Pooling layer Max pooling 2.png)\n",
    "\n",
    "同时也有平均池化层，但平均池化层不常用。\n",
    "\n",
    "![Pooling layer Average pooling.png](img/Pooling layer Average pooling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
