{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 计算机视觉\n",
    "\n",
    "随着深度学习的兴起，近些年来计算机视觉领域的发展十分迅猛。一方面，深度学习在计算机视觉的应用，使得很多几年前还无法解决的领域问题得以解决，比如人脸识别、自动驾驶；另一方面，在实践中计算机视觉社区对深度学习技巧的发现，也常常可以应用到其它领域里。\n",
    "\n",
    "计算机视觉领域的典型问题，包括图片分类、物体检测、神经风格迁移等。\n",
    "\n",
    "![Computer Vision Problems.png](img/Computer Vision Problems.png)\n",
    "\n",
    "由于图像数据的特点（高分辨率，特征多），非常容易多拟合，同时针对图像数据训练模型也需要极大的计算资源。而要使用高分辨率的图片训练模型，最好要实现卷积，卷积是卷积神经网络的基本组成单元。\n",
    "\n",
    "![Deep Learning on large images.png](img/Deep Learning on large images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. 边缘检测实例\n",
    "\n",
    "在之前介绍的人类识别神经网络中，我们发现最终训练完成的神经网络会首先形成边缘检测的底层特征，在此基础上继续构建五官检测，进而再到人脸检测。可以说边缘检测是非常基础性的步骤。\n",
    "\n",
    "![Computer Vision Problem.png](img/Computer Vision Problem.png)\n",
    "\n",
    "卷积操作可以有效地进行边缘检测。卷积计算用到的这个3×3的矩阵，称为**过滤器 filter**，有些文献中也称为**核 kernel**。\n",
    "\n",
    "![Vertical edge detection.png](img/Vertical edge detection.png)\n",
    "\n",
    "卷积操作检测出来的边缘看起来比较粗，当输入图片的分辨率非常高时，这点损耗可以忽略不计。\n",
    "\n",
    "![Vertical edge detection 2.png](img/Vertical edge detection 2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. 更多边缘检测的内容\n",
    "\n",
    "上面提到的过滤器，还可以区分由浅到深的边缘和由深到浅的边缘。\n",
    "\n",
    "![Vertical edge detection examples.png](img/Vertical edge detection examples.png)\n",
    "\n",
    "而将这个过滤器的矩阵转置，就是水平边缘检测的过滤器。\n",
    "\n",
    "![Vertical and Horizontal Edge Detection.png](img/Vertical and Horizontal Edge Detection.png)\n",
    "\n",
    "除去水平边缘和垂直边缘过滤器外，计算机视觉社区还发明过Sober过滤器和Scharr过滤器，它们分别有一些自己的特性。而在深度学习时代，一个非常重要的理念是，过滤器本身可以作为神经网络的参数，在反向传播的过程中进行学习。这样最终学得的边缘检测过滤器，可能不限于水平或垂直边缘，而是可以检测任意倾斜的边缘。\n",
    "\n",
    "![Learning to detect edges.png](img/Learning to detect edges.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 补全\n",
    "\n",
    "经过卷积操作，图片的分辨率会降低。如果原图是n×n的矩阵，而过滤器是f×f的矩阵，卷积之后的矩阵就变为了(n-f+1)×(n-f+1)维。这样有两个坏处：1）随着每一层神经网络的卷积计算，图片的大小都在不断缩小，限制了训练过大的神经网络；2）角和边上的像素点，参与卷积计算的次数会更少，从而造成边角的信息利用率低。所以实际使用中，卷积通常伴随着补全。\n",
    "\n",
    "![Padding.png](img/Padding.png)\n",
    "\n",
    "根据使用补全的策略，区分**正确卷积 Valid convolution**和**同一卷积 Same convolution**。所谓正确卷积，就是不包含补全，任由图片大小缩减；而同一卷积，是先进行补全，使得最终输出的图片大小和输入一致。注意要同一卷积的要求，使得 $p=\\frac{f-1}{2}$。这就要求过滤器是一个奇数维的矩阵，否则补全就需要是非对称的。过滤器是奇数维矩阵的另一个好处，是过滤器存在一个中心像素，方便定位位置。\n",
    "\n",
    "![Valid and Same convolutions.png](img/Valid and Same convolutions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 步长\n",
    "\n",
    "前面看到的卷积操作，过滤器每次都只移动一格。而引入步长的概念之后，过滤器每次可以移动不只一格。\n",
    "\n",
    "![Strided convolution.png](img/Strided convolution.png)\n",
    "\n",
    "在有补全和步长的情况下，输出的数据量大小也会有所变化。\n",
    "\n",
    "![Summary of convolutions.png](img/Summary of convolutions.png)\n",
    "\n",
    "从严格数学的定义来说，实际上我们上面用到的应该称为**交叉相关性 cross-correlation**，而真正的卷积，在交叉相关性之前，还需要先进行垂直和水平的翻转，这样可以使得卷积服从结合律。不过这个特性对于神经网络意义不大（对于信号处理中使用卷积比较有用），所以在深度学习社区，实际上使用卷积时，并不会进行翻转，但是从命名习惯上，依然将其称之为卷积。\n",
    "\n",
    "![Technical note on cross-correlation vs convolution.png](img/Technical note on cross-correlation vs convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 高维空间的卷积\n",
    "\n",
    "对于图片，如果要处理RGB值，就会有三个n×n的矩阵，形成一个n×n×3的立方体，这时相应的，过滤器也变成了一个f×f×3的立方体，最终输出仍然是一个矩阵。\n",
    "\n",
    "![Convolutions on RGB image.png](img/Convolutions on RGB image.png)\n",
    "\n",
    "在需要的情况下，也可以同时使用多个过滤器。\n",
    "\n",
    "![Multiple filters.png](img/Multiple filters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7. 一层卷积神经网络\n",
    "\n",
    "![Example of a layer.png](img/Example of a layer.png)\n",
    "\n",
    "![Summary of notation.png](img/Summary of notation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8. 简单的卷积神经网络示例\n",
    "\n",
    "一个39×39像素，RGB三通道表示的图片，经过三个卷积层，最后叠加一层logistic或softmax的卷机神经网络分类模型。注意到随着层数的增加，图片的像素在下降，而通道数在上升，这也是超参选择（每一层的过滤器大小f，过滤器数量$n_c$，步长s，补全p）的一个普遍趋势。\n",
    "\n",
    "![Example ConvNet.png](img/Example ConvNet.png)\n",
    "\n",
    "实际上，一个典型的卷积神经网络，除去卷积层之外，还会包含池化层(Pooling)，完全连接层(Fully connected)。下面会详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. 池化层\n",
    "\n",
    "在过滤器区间内，取最大值，称为最大池化层。\n",
    "\n",
    "![Pooling layer Max pooling.png](img/Pooling layer Max pooling.png)\n",
    "\n",
    "池化层和卷积层的一个显著不同，是池化层的过滤器是针对通道独立的，不会跨通道取最大值。过滤器也包含两个超参，分别是f过滤器大小和步长s。注意和卷积层的另一个不同，是池化层的过滤器，只有超参，没有参数。所以在反向传播的过程中，这一层是没有更新的。\n",
    "\n",
    "![Pooling layer Max pooling 2.png](img/Pooling layer Max pooling 2.png)\n",
    "\n",
    "同时也有平均池化层，但平均池化层不常用。\n",
    "\n",
    "![Pooling layer Average pooling.png](img/Pooling layer Average pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. 卷积神经网络实例\n",
    "\n",
    "上面说到，池化层是没有需要学习的参数的，而且池化层通常会跟在一层或多层卷积层之后，所以习惯上会将卷积层和池化层一起称为神经网络的一层。而所谓的完全连接层FC，就是普通的神经网络的一层，有权重和截距作为参数。\n",
    "\n",
    "下图是一个卷积-池化-卷积-池化-全连接-全连接-全连接-Softmax的卷积神经网络的例子。设计良好的卷积神经网络架构，每一层激活值的数量在前向传播的过程中，通常是逐渐递减的。\n",
    "\n",
    "![Convolution Neural Network Example.png](img/Convolution Neural Network Example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 11. 为何卷积有效\n",
    "\n",
    "卷积层相比全连接层，需要学习的参数大幅减少，有以下两个原因：\n",
    "    - 参数共享：一个特征检测器（比如垂直边缘检测器），可能不只对图像的单一区域有效。过滤器平移的过程，就是参数共享的过程。\n",
    "    - 连接的稀疏性：每一层的输出值都只依赖与几个输入值。（与全连接层相比，所有输入和所有输出都是连通的）\n",
    "    \n",
    "![Why convolutions.png](img/Why convolutions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 12. 卷积神经网络：一步一步地搭建卷积模型\n",
    "\n",
    "这里我们将使用numpy来实现卷积神经网络的卷积层（CONV）和池化层（POOL），前向传播与反向传播。\n",
    "\n",
    "**标记**:\n",
    "- 上标 $[l]$ 表示第 $l^{th}$ 层的对应变量。 \n",
    "    - 举例: $a^{[4]}$ 是第 $4^{th}$ 层激活层。 $W^{[5]}$ 和 $b^{[5]}$ 是第 $5^{th}$ 层的参数。\n",
    "\n",
    "\n",
    "- 上标 $(i)$ 表示第 $i^{th}$ 个样本的对应变量。 \n",
    "    - 举例: $x^{(i)}$ 是第 $i^{th}$ 个训练样本的输入。\n",
    "    \n",
    "    \n",
    "- 下标 $i$ 表示向量的第 $i^{th}$ 个元素。\n",
    "    - 举例: $a^{[l]}_i$ 表示第 $l$ 层的激活值的第 $i^{th}$ 个元素，假定这一层是全连接层（FC）。\n",
    "    \n",
    "    \n",
    "- $n_H$, $n_W$ 和 $n_C$ 分别表示给定层的高度、宽度和通道数。当需要确定地表示是第 $l$ 层时，可以写作\n",
    "$n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$。\n",
    "- $n_{H_{prev}}$, $n_{W_{prev}}$ 和 $n_{C_{prev}}$ 分别表示上一层的高度、宽度和通道数。当需要确定地表示是第 $l$ 层对应的前一层相应参数时，可以写作 $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 三方包\n",
    "\n",
    "首先引入在这个编程练习中所需要的包。\n",
    "- [numpy](www.numpy.org) 是Python生态圈中进行科学计算的基础包。\n",
    "- [matplotlib](http://matplotlib.org) 是Python生态圈中著名的绘图包。\n",
    "- np.random.seed(1) 用来保证所有函数调用中随机部分的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 12.2 总览\n",
    "\n",
    "我们将会实现卷积神经网络的各个组件：\n",
    "\n",
    "- 卷积函数，包括：\n",
    "    - 零补全 Zero Padding\n",
    "    - 卷积窗口 Convolve window \n",
    "    - 前向卷积 Convolution forward\n",
    "    - 反向卷积 Convolution backward (optional)\n",
    "- 池化函数，包括:\n",
    "    - 前向池化 Pooling forward\n",
    "    - 创建掩码 Create mask \n",
    "    - 分布值 Distribute value\n",
    "    - 反向池化 Pooling backward (optional)\n",
    "\n",
    "这一节的内容都基于 `numpy` 从头开始实现；而在下一节中，我们会用Tensorflow来实现同样的模型。\n",
    "\n",
    "<img src=\"img/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "**注意** 每一个前向传播的函数，都有对应的反向传播的函数。因此，前向传播模块中的每一步，都需要将相应的参数保存到缓存中。这些参数将在反向传播过程中用于计算梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 12.3 卷积神经网络\n",
    "\n",
    "编程框架使得卷积非常容易使用，但卷积的概念依然是深度学习中最难理解的概念之一。卷积层将输入立方体转换为另一个尺寸的输出立方体，如下图所示：\n",
    "\n",
    "<img src=\"img/conv_nn.png\" style=\"width:350px;height:200px;\">\n",
    "\n",
    "在这一节，我们会逐步构建起一个完整的卷积层。首先，我们需要实现两个辅助函数：零补全和卷积计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.3.1 零补全\n",
    "\n",
    "零补全围绕着图像的边框补零值：\n",
    "\n",
    "<img src=\"img/PAD.png\" style=\"width:600px;height:400px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **Zero-Padding**<br> Image (3 channels, RGB) with a padding of 2. </center></caption>\n",
    "\n",
    "补全的主要好处包括：\n",
    "\n",
    "- 使用卷积层时，高度和宽度不会缩减，这点对于构建深度网络来说十分重要。而一个重要的应用实例就是同一补全的卷积层，卷积计算前后，高度和宽度都不变。\n",
    "\n",
    "- 使得图片边框的信息得到充分利用。没有补全时，下一层只有很少的数值会收到当前图片的边角像素的影响。\n",
    "\n",
    "**练习**: 实现下面的函数，批量将样本 X 进行零补全。[使用 np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)。注意到如果想要给形状为 $(5,5,5,5,5)$ 的数组 \"a\" 在第二维度补 1，在第四维度补 3，其它维度补 0，可以这样写：\n",
    "```python\n",
    "a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), 'constant', constant_values = (..,..))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: zero_pad\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[1,1] = [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] = [[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c44fdce10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAACqCAYAAAAz+v3EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEtRJREFUeJzt3X2wXHV9x/H3J2AYSEiUBxNLCAoIKY42pGMkk6ZEBQzY\nEv+w9anloVUZhcrUjg9NmTHO2FT/cBQURzEYedBKZYQEJW3iQKVBEiNJIEqCYQATYhIRSGgSK4F8\n+8c5N7Pc7MPZ3d/ds3fP5zWzc8/u/u73fO/u2e89Z8/v/H6KCMzMqmpM2QmYmZXJRdDMKs1F0Mwq\nzUXQzCrNRdDMKs1F0MwqzUXQzFqSdKmk/yk7j5HgImhmRQ1kp2IXQTOrNBfBkkk6VdIzkqbn9/9I\n0m8l/XnZuVn/6GQ7kXSvpEWS1kjaI+kOSa+sef4/JO2Q9Jyk/5Z0Vs1zx0lalv/eauC0Ef0DS+Qi\nWLKIeBz4JHCrpKOBJcCSiLiv3Mysn3SxnfwtcBkwGXgJ+ErNc3eTFbdXA+uA79Q89zVgPzAJ+Hvg\n77r/K/qTfO1wf5B0J3AqcBB4c0QcKDkl60PtbCeS7gUeiIgF+f0/BtYDR8ewD36+h/gsMBHYB/wf\n8IaI2JI//6/AnIgYuCMU7wn2j8XAG4CvuABaE+1uJ9tqln8NjAVOkDRG0uclPSZpN/AE2YmPE4AT\ngSOAp4b97kByEewDksYBXwZuBBbWfm9jNqTD7eTkmuVTgBeA3wEfAP4SeFtEvBJ4LaD89jTw4rDf\nndpt/v3KRbA/XAf8LCI+TPY9zTdKzsf6Uyfbyd9ImibpGOCzwPfzQ+HxwB+A5/Li+m/kXWAi4iDw\nA7JCe3R+wuTS9H9Of3ARLJmki4ELgI/mD30cOFvS+8rLyvpNF9vJLcBNwG/IDoWvzh+/GdgKbAd+\nAfx02O/9A3AssAP4Vn4bSF2dGJH0KuA2st3sJ4G/jog9ddo9Cewh+zL3QETM7HilZlZIfmLklogY\n2AKWQrd7gp8GfhwRZwL3AP/coN1BYG5EnO0CaGb9pNsiOJ9sV5v857satFOCdZnZMJL+V9LzNbeh\n+7MZ0MvcUuv2cPjZiDiu0f2axx8HdpN11rwhIr7Z8UrNzBI6slUDSSvJeo0feojsP8w1dZo3qqiz\nI2KHpBOBlZI2RcSqtrM1M0usZRGMiPMbPSdpl6RJEbFL0mTgtw1i7Mh/Pi3pDmAmULcISvIufEVF\nhEZ6Hd6+qq3eNtayCLawjOy6xC+Q9SNaOrxB3j9pTETszfsjXUDWX6mh559/vsu0Xm7RokUsWLAg\nacwJEyYkjTeSFi9enDTe0qVLmT9/ftKYH/zgB5PGa2b27NlNn9+6dStTp3bfN9hxehOnaKz777+/\n7uPdnqz4AnC+pEeBtwOfB5D0Gkk/zNtMAlZJWg+sBu6KiBVdrtfMLImu9gQj4lngvDqP7wD+Il9+\nApjezXrMzEZKJbqtzJkzp+wUBsqZZ55Zdgp1SZonabOkX0n6VKdxJk6cmCQfx+lNnG5juQha26ZN\nm1Z2CoeRNAb4KvAOslFW3iepo0T77UPuOCMbqxJF0CphJrAlIn6dDzH1PbLO/GZNuQjaoDiJl4+d\n91T+mFlTLoJmVmnd9hM06xfbefnAn1Pyxw6zdevWQ8sTJ05M+t2U9Y89e/awZ89hg1odxkXQBsVa\n4HRJp5CNgfdeoO5Ye6k66Fp/G/4Pbtu2bXXbuQjaQIiIlyRdBawg+5rnxojYVHJaNgq4CNrAiIj/\nBPqzE6P1LZ8YMbNKcxE0s0pzETSzSktSBItcsynpOklbJG2Q5AEVzKwvdF0Ei1yzKelC4LSIeD1w\nBfD1btdrZpZCij3BItdszieb55SIWANMlDQJM7OSpSiCRa7ZHN5me502ZmY95xMjZlZpKTpLF7lm\ncztwcos2hyxatOjQ8pw5czwe4ADavHkzjz76aNlpmCUpgkWu2VwGXAncJukcYHdE7GoUMPWkSNZ/\npk2b9rLBWe+6666uY0q6kWxah10R8aauA1oldH04HBEvAUPXbP4S+F5EbJJ0haQP523uBp6Q9Bjw\nDeCj3a7XrI4lZL0UzApLcu1wvWs2I+Ibw+5flWJdZo1ExKr8iMSsMJ8YMbNKcxE0s0rzUFpWOR5Z\nuho8srRVlfJbQx5ZuhqKjiztw2EbGJK+C/wUOEPSVkmXl52T9T/vCdrAiIj3l52DjT7eEzSzSnMR\nNLNKcxE0s0pzETSzSnMRNLNK89lhs5ItX748SZwJEyYkibN48eIkcZYsWZIkzkjryURLks6VtFvS\nuvx2TYr1mpl1q+s9wZqJlt4O/AZYK2lpRGwe1vS+iLi42/WZmaXUq4mWoMWlTGZmZejVREsAs/I5\nh38k6awE6zU7RNIUSfdI+qWkjZI+VnZONjr06sTIg8DUiNifz0F8J3BGj9Zt1fAi8PGI2CBpPPCg\npBV1vpYxe5meTLQUEXtrlpdL+pqk4yLi2XoBv/jFLx5anjt3LnPnzk2QZlqXXnpp2SkUdt5555Wd\nwmEeeOABVq9enSxeROwEdubLeyVtIjsicRG0pnoy0ZKkSUMTK0maCahRAQRYuHBhgrSsn82aNYtZ\ns2Ydun/ttdcmiy3ptcB0YE2yoDawui6CEfGSpKGJlsYANw5NtJQ9HTcA75b0EeAA8HvgPd2u16ye\n/FD4duDq2iMQs0Z6MtFSRFwPXJ9iXWaNSDqSrADeEhFLG7XzyNLV4JGlrYq+BTwSEU2PrT2ydDV4\nZGmrFEmzgQ8Ab5O0Pr8yaV7ZeVn/856gDYSIuB84ouw8bPTxnqCZVZqLoJlVmougmVWai6CZVZqL\noJlVms8Om5Xs2GOPTRIn1fXsqa41r9TI0mZmo5WLoJlVmougmVWai6CZVVqq2eZulLRL0sNN2lwn\naUs+xP70FOs1GyLpKElr8uuGN0r6TNk52eiQak9wCfCORk/mQ+qfFhGvB64Avp5ovWYARMQfgLdG\nxNlkA6pemA/ga9ZUkiIYEauA55o0mQ/cnLddA0yUNCnFus2GRMT+fPEosu5fUWI6Nkr06jvB4TPS\nbaf+jHRmHZM0RtJ6srlGVkbE2rJzsv7Xl52la+cY6deJlqw7qSdaAoiIg8DZkiYAd0o6KyIeGd7O\nI0tXQ7+NLL0dOLnm/mEz0tXyREuDbyQnWoqI5yXdC8wDDiuCHlm6GsoYWVr5rZ5lwCUAks4Bdg/N\nPmeWgqQTJE3Ml48GzsfTbVoBSfYEJX0XmAscL2kr8BlgLPlscxFxt6SLJD0G7AMuT7FesxqvAW6S\nNIbsn/ttEXF3yTnZKJBqtrn3F2hzVYp1mdUTERuBGWXnYaOPrxgxs0pzETSzSnMRNLNKcxE0s0rr\ny87SZlUyefLkJHFuvfXWJHHmzUszZ/3xxx+fJM5I856gmVWai6CZVZqLoJlVmougmVWai6ANlHw4\nrXWSlpWdi40OLoI2aK6mzsgxZo24CNrAkDQFuAhYXHYuNnr0ZKIlSedK2p0fpqyTdE2K9ZoN8yXg\nE3hYfWtDTyZayt0XETPy2+cSrdcMAEnvBHZFxAaaj21p9jKphtJaJemUFs28UdpImg1cLOki4Gjg\nWEk3R8Qlwxt6eP1q6Lfh9QFmSdpANqz+J+rN/WDWqYhYACyA7OsX4J/qFUDw8PpVUXR4/V4VwQeB\nqRGxP5+D+E7gjEaNU11LOZJSXafZC6muBTUbRD0pghGxt2Z5uaSvSTouIp6t137v3kPNGTt2LGPH\nju1BltZL+/btY//+/a0bdiAifgL8ZESC28BJWQQbfhktadLQxEqSZgJqVAABxo8fnzAt60fjxo1j\n3Lhxh+4/88wzJWZjVdaTiZaAd0v6CHAA+D3wnhTrNTPrVk8mWoqI64HrU6zLzCwlXzFiZpXmkaXN\nSnb66acnibNw4cIkcUbLiNCpeE/QzCrNRdDMKs1F0MwqzUXQzCrNJ0ZsYEh6EtgDHAQORMTMcjOy\n0cBF0AbJQWBuRDxXdiI2evhw2AaJ8DZtbfIGY4MkgJWS1kr6UNnJ2Ojgw2EbJLMjYoekE8mK4aaI\nWFV2UtbfXARtYETEjvzn05LuAGYChxVBjyxdDT0bWTqf4etmYBLZF9PfjIjr6rS7DrgQ2Adcls8F\nYZaEpGOAMRGxV9I44ALgs/XaemTpaujlyNIvAh+PiA2SxgMPSloREZuHGuSjSZ8WEa+X9Bbg68A5\nCdZtNmQScIekINuuvxMRK0rOyUaBrotgROwEdubLeyVtAk4CNtc0m0+2t0hErJE0sXagVbNuRcQT\nwPSy87DRJ+nZYUmvJdsQ1wx76iSgdl90e/6YmVmpkhXB/FD4duDq2jlFzMz6Warh9Y8kK4C3RMTS\nOk22AyfX3J+SP1aXJ1oafCM50ZJZO1J1kfkW8EhEXNvg+WXAlcBtks4Bdjf7PtATLQ0+T7Rk/SJF\nF5nZwAeAjZLWk/XaXwCcQj7RUkTcLekiSY+RdZG5vNv1mpmlkOLs8P3AEQXaXdXtuszMUvO1w2ZW\naS6CZlZpLoJmVmkugjYw8iuRvi9pk6Rf5pdomjXlUWRskFwL3B0Rf5X3XT2m7ISs/7kI2kCQNAGY\nExGXAUTEi8DzpSZlo4IPh21QvA74naQlktZJukHS0WUnZf3PRdAGxZHADOD6iJgB7Ac+XW5KNhr4\ncNgGxVPAtoj4eX7/duBT9Rp6ZOlq6NnI0mb9ICJ2Sdom6YyI+BXwduCRem09snQ19HJkabN+8THg\nO5JeATyOr1G3AlwEbWBExEPAm8vOw0aXrk+MSJoi6Z68c+pGSR+r0+ZcSbvzs3brJF3T7XrNzFJI\ncXZ4aKKlNwCzgCslTavT7r6ImJHfPpdgvYW98MILyWM+9NBDlY25b9++5DH7SZEv0x2nf+J0G6vr\nIhgRO4emz8yH1R+aaGk4dbuuTrkIpjXoI0L324fccUY2Vq8mWgKYJWmDpB9JOivles3MOpXsxEiL\niZYeBKZGxP58DuI7gTNSrdvMrFOKiO6DZBer/xBY3mSekdr2TwB/GhHP1nmu+4RsVIqIEf/KxNtX\ntdXbxnoy0VLtROuSZpIV38MKYKMkzVLx9mXD9WSiJeDdkj4CHAB+D7yn2/WamaWQ5HDYzGy0KnUU\nGUmvkrRC0qOS/ktS3SvZJT0p6SFJ6yX9rEGbeZI2S/qVpLoXzku6TtKW/Cz19AL5NY3ZSSdwSTdK\n2iXp4SZt2s2zacwO82zZCb7dXPu9Y32RbahgnJbvccE4hd6DAnGOkrQm//xslPSZLvMak783y7qI\n0fIzXTBO96OJR0RpN+ALwCfz5U8Bn2/Q7nHgVU3ijAEeIzsEfwWwAZg2rM2FwI/y5bcAq1vkViTm\nucCyNv/mPyPrRvRwg+fbyrNgzE7ynAxMz5fHA48meE2LxGw710TbYsv3O9V7nPI9aCPWMfnPI4DV\nwMwu8vpH4NZu3qdWn+k24nwbuDxfPhKY0G6MsscTnA/clC/fBLyrQTvRfK91JrAlIn4dEQeA7+Wx\nh6/rZoCIWANMlDSpy5hDuRUWEauA55o0aTfPIjE7ybNIJ/i2ci0Ys+1cEyn6frdU8P0oEqfo61Uk\n1lAP96PIikVH34NJmgJcBCzu5PdrQ9HlkWjNaOJLIBtNPCLaHk287CL46sjPGkfETuDVDdoFsFLS\nWkkfqvP8SUDtODlPcfjGMrzN9jpt2o0J6TuBt5tnUR3n2aQTfMe59mHH+qLvdylavF5Ffn9MfuJy\nJ7AyItZ2mMqXgE/QYRGt0eozXUSS0cRHfBQZSSuB2r0Dkb0A9b7rafTCzo6IHZJOJHvhNuX/bcs2\nWjqBd5ynmneC70iLmKPlNe2ZFO9BRBwEzs73nu6UdFZE1B1vsUke7wR2RcQGSXPpbo89xWd6aDTx\nKyPi55K+TDaaeFvfeY74nmBEnB8Rb6q5vTH/uQzYNXT4JGky8NsGMXbkP58G7iA7dKm1HagdKXNK\n/tjwNie3aNNWzIjYO3SYERHLgVdIOq5JzCLazbOlTvNU1gn+duCWiFiaItdWMUfoNS2iyDbUcwXe\ng7bkh4v3AvM6+PXZwMWSHgf+HXirpJs7zKPVZ7qIeqOJz2g3SNmHw8uAy/LlS4HD3mRJx+T/CZE0\nDrgA+MWwZmuB0yWdImks8N489vB1XZLHOQfYPXQo3kDLmLXff6lFJ/DhfxaN/4u2m2fLmF3k2bQT\nfIe5tuxY32Gu3SqyDbWj2XvcjlbvQetEpBOU97zIDxfPBza3GyciFkTE1Ig4lez1uSciLukgnyKf\n6SL57AK2SRo6Umg4mnirQKXdgOOAH5Od9VoBvDJ//DXAD/Pl15GdqVsPbAQ+3SDWvDzOlqE2wBXA\nh2vafJXsDOBDwIwC+TWNCVxJ9uatB34KvKVAzO8CvwH+AGwlG/242zybxuwwz9nASzWv/br89eg4\n1yIxO8k14fZ42PvdYZzD3o8O49R9vTqI88b8dzcADwP/kuC16vgsftHPdMFYf0L2D2wD8ANgYrsx\n3FnazCqt7MNhM7NSuQiaWaW5CJpZpbkImlmluQiaWaW5CJpZpbkImlmluQiaWaX9P0BfssqyjIfe\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c88856128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[1,1] =\", x[1,1])\n",
    "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **x.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (4, 3, 3, 2)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **x_pad.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (4, 7, 7, 2)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **x[1,1]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [[ 0.90085595 -0.68372786]\n",
    " [-0.12289023 -0.93576943]\n",
    " [-0.26788808  0.53035547]]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **x_pad[1,1]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [[ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
