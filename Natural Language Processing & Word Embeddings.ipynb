{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理&词嵌入 Natural Language Processing & Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 词嵌入简介 Introduction to Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 词汇表征 Word Representation\n",
    "\n",
    "此前对于词的表示：用词典，配合One-Hot编码。算法很难发现词与词之间的关系，也就无法利用同义词或同属性词的关系来做推断。任意两个One-Hot编码的向量的内积都是0。\n",
    "\n",
    "如果用特征来表示词呢？比如每个词都有诸如性别、年龄、食物等等[-1, 1]区间内的特征。这样如果有 $e$ 个特征，那么每个词都可以表示为 $e$ 维的向量。向量之间的相似度，可以给算法更多信息进行推断。\n",
    "\n",
    "而所谓词嵌入，就是用来寻找这样高维特征的办法。\n",
    "\n",
    "有了高维特征之后，人们也经常会将其降维到二维特征进行可视化。一个常见的算法是t-SNE。\n",
    "\n",
    "词嵌入是自然语言处理中一个非常重要的技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 使用词嵌入 Using Word Embeddings\n",
    "\n",
    "以命名实体识别问题为例，只需要将词汇的One-Hot向量替换为特征向量即可。具体步骤：\n",
    "\n",
    "1. 从一个非常大（上亿级别）的语料库中，学习词嵌入；（或者下载提前训练好的）\n",
    "2. 将词嵌入，迁移学习到一个具有相对小训练集（比如10万的词汇）的任务，比如命名实体识别；\n",
    "3. 可选：用新的数据继续对词嵌入调参\n",
    "\n",
    "当训练集的数量相对较小时，使用词嵌入能大幅提高NLP问题的效果，比如命名实体识别、文本摘要（text summarization）、指代消解（co-reference resolution）、句法分析（parsing）。而对于语言模型、机器翻译则帮助不大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 词嵌入的特性 Properties of Word Embeddings\n",
    "\n",
    "词嵌入还可以用来帮助解决**类比推理 analogy reasoning**问题，Man is to Woman as King is to ? 只需要计算 $e_{man} - e_{woman} \\approx e_{king} - e_{?}$，这个公式可以正规地定义为对cosine相似度求最小值的优化问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 嵌入矩阵 Embedding Matrix\n",
    "\n",
    "学习词嵌入，最终就是为了学习 #features × #words 的嵌入矩阵。用 $E$ 表示嵌入矩阵，$o_i$ 表示第 $i$ 个词的One-Hot向量，$e_i$ 表示第 $i$ 个词的嵌入向量，则有 $ E \\cdot o_i = e_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学习词嵌入：Word2vec & GloVe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 学习词嵌入 Learning Word Embeddings\n",
    "\n",
    "[A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 Word2Vec\n",
    "\n",
    "[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Negative Sampling\n",
    "\n",
    "[Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 GloVe word vectors\n",
    "\n",
    "[GloVe: Global Vectors for Word Representation](https://www.aclweb.org/anthology/D14-1162)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 词嵌入的应用 Applications using Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 情感分类 Sentiment Classification\n",
    "\n",
    "方法1：将句子每个词的词嵌入向量做平均（或求和），然后喂给Softmax分类器。缺点：没有考虑词的顺序信息。\n",
    "\n",
    "方法2：运用每个词的词嵌入向量，喂给RNN，最后输出Softmax。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 词嵌入除偏 Debiasing Word Embeddings\n",
    "\n",
    "[Man is to Computer Programmer as Woman is to Homemaker?\n",
    "Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
